{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주의! ray를 tensorflow보다 먼저 import하면 오류가 발생할 수 있습니다\n",
    "import io, json, os, math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Add, Concatenate, Lambda\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, MaxPool2D\n",
    "from tensorflow.keras.layers import UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import ray\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856562f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "PROJECT_PATH = os.path.join(os.getcwd(), 'data')\n",
    "IMAGE_PATH = os.path.join(PROJECT_PATH, 'images')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models')\n",
    "TFRECORD_PATH = os.path.join(PROJECT_PATH, 'tfrecords_mpii')\n",
    "TRAIN_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'train.json')\n",
    "VALID_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'validation.json')\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5634585",
   "metadata": {},
   "source": [
    "0 - 오른쪽 발목\n",
    "1 - 오른쪽 무릎\n",
    "2 - 오른쪽 엉덩이\n",
    "3 - 왼쪽 엉덩이  \n",
    "\n",
    "4 - 왼쪽 무릎\n",
    "5 - 왼쪽 발목\n",
    "6 - 골반\n",
    "7 - 가슴(흉부)  \n",
    "\n",
    "8 - 목\n",
    "9 - 머리 위\n",
    "10 - 오른쪽 손목\n",
    "11 - 오른쪽 팔꿈치  \n",
    "\n",
    "12 - 오른쪽 어깨\n",
    "13 - 왼쪽 어깨\n",
    "14 - 왼쪽 팔꿈치\n",
    "15 - 왼쪽 손목"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c3bb9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"joints_vis\": [\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"joints\": [\n",
      "    [\n",
      "      620.0,\n",
      "      394.0\n",
      "    ],\n",
      "    [\n",
      "      616.0,\n",
      "      269.0\n",
      "    ],\n",
      "    [\n",
      "      573.0,\n",
      "      185.0\n",
      "    ],\n",
      "    [\n",
      "      647.0,\n",
      "      188.0\n",
      "    ],\n",
      "    [\n",
      "      661.0,\n",
      "      221.0\n",
      "    ],\n",
      "    [\n",
      "      656.0,\n",
      "      231.0\n",
      "    ],\n",
      "    [\n",
      "      610.0,\n",
      "      187.0\n",
      "    ],\n",
      "    [\n",
      "      647.0,\n",
      "      176.0\n",
      "    ],\n",
      "    [\n",
      "      637.0201,\n",
      "      189.8183\n",
      "    ],\n",
      "    [\n",
      "      695.9799,\n",
      "      108.1817\n",
      "    ],\n",
      "    [\n",
      "      606.0,\n",
      "      217.0\n",
      "    ],\n",
      "    [\n",
      "      553.0,\n",
      "      161.0\n",
      "    ],\n",
      "    [\n",
      "      601.0,\n",
      "      167.0\n",
      "    ],\n",
      "    [\n",
      "      692.0,\n",
      "      185.0\n",
      "    ],\n",
      "    [\n",
      "      693.0,\n",
      "      240.0\n",
      "    ],\n",
      "    [\n",
      "      688.0,\n",
      "      313.0\n",
      "    ]\n",
      "  ],\n",
      "  \"image\": \"015601864.jpg\",\n",
      "  \"scale\": 3.021046,\n",
      "  \"center\": [\n",
      "    594.0,\n",
      "    257.0\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    json_formatted_str = json.dumps(train_annos[0], indent=2)\n",
    "    print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb5aede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def parse_one_annotation(anno, image_dir):\n",
    "    filename = anno['image']\n",
    "    joints = anno['joints']\n",
    "    joints_visibility = anno['joints_vis']\n",
    "    annotation = {\n",
    "        'filename': filename,\n",
    "        'filepath': os.path.join(image_dir, filename),\n",
    "        'joints_visibility': joints_visibility,\n",
    "        'joints': joints,\n",
    "        'center': anno['center'],\n",
    "        'scale' : anno['scale']\n",
    "    }\n",
    "    return annotation\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a722691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': '015601864.jpg', 'filepath': '/aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/images/015601864.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[620.0, 394.0], [616.0, 269.0], [573.0, 185.0], [647.0, 188.0], [661.0, 221.0], [656.0, 231.0], [610.0, 187.0], [647.0, 176.0], [637.0201, 189.8183], [695.9799, 108.1817], [606.0, 217.0], [553.0, 161.0], [601.0, 167.0], [692.0, 185.0], [693.0, 240.0], [688.0, 313.0]], 'center': [594.0, 257.0], 'scale': 3.021046}\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    test = parse_one_annotation(train_annos[0], IMAGE_PATH)\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b4c457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def generate_tfexample(anno):\n",
    "\n",
    "    # byte 인코딩을 위한 함수\n",
    "    def _bytes_feature(value):\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy()\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    filename = anno['filename']\n",
    "    filepath = anno['filepath']\n",
    "    with open(filepath, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = Image.open(filepath)\n",
    "    if image.format != 'JPEG' or image.mode != 'RGB':\n",
    "        image_rgb = image.convert('RGB')\n",
    "        with io.BytesIO() as output:\n",
    "            image_rgb.save(output, format=\"JPEG\", quality=95)\n",
    "            content = output.getvalue()\n",
    "\n",
    "    width, height = image.size\n",
    "    depth = 3\n",
    "\n",
    "    c_x = int(anno['center'][0])\n",
    "    c_y = int(anno['center'][1])\n",
    "    scale = anno['scale']\n",
    "\n",
    "    x = [\n",
    "        int(joint[0]) if joint[0] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "    y = [\n",
    "        int(joint[1]) if joint[1] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "\n",
    "    v = [0 if joint_v == 0 else 2 for joint_v in anno['joints_visibility']]\n",
    "\n",
    "    feature = {\n",
    "        'image/height':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/depth':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[depth])),\n",
    "        'image/object/parts/x':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=x)),\n",
    "        'image/object/parts/y':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
    "        'image/object/center/x': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_x])),\n",
    "        'image/object/center/y': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_y])),\n",
    "        'image/object/scale':\n",
    "        tf.train.Feature(float_list=tf.train.FloatList(value=[scale])),\n",
    "        'image/object/parts/v':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=v)),\n",
    "        'image/encoded':\n",
    "        _bytes_feature(content),\n",
    "        'image/filename':\n",
    "        _bytes_feature(filename.encode())\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a28291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def chunkify(l, n):\n",
    "    size = len(l) // n\n",
    "    start = 0\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        results.append(l[start:start + size])\n",
    "        start += size\n",
    "    return results\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd12daa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "64\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "test_chunks = chunkify([0] * 1000, 64)\n",
    "print(test_chunks)\n",
    "print(len(test_chunks))\n",
    "print(len(test_chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e967830c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def build_single_tfrecord(chunk, path):\n",
    "    print('start to build tf records for ' + path)\n",
    "\n",
    "    with tf.io.TFRecordWriter(path) as writer:\n",
    "        for anno in chunk:\n",
    "            tf_example = generate_tfexample(anno)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    print('finished building tf records for ' + path)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f78f0265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def build_tf_records(annotations, total_shards, split):\n",
    "    chunks = chunkify(annotations, total_shards)\n",
    "    futures = [\n",
    "        build_single_tfrecord.remote(\n",
    "            chunk, '{}/{}_{}_of_{}.tfrecords'.format(\n",
    "                TFRECORD_PATH,\n",
    "                split,\n",
    "                str(i + 1).zfill(4),\n",
    "                str(total_shards).zfill(4),\n",
    "            )) for i, chunk in enumerate(chunks)\n",
    "    ]\n",
    "    ray.get(futures)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a656383",
   "metadata": {},
   "source": [
    "- Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8419d5ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 08:01:21,757\tWARNING services.py:1729 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=3.32gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to parse annotations.\n",
      "First train annotation:  {'filename': '015601864.jpg', 'filepath': '/aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/images/015601864.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[620.0, 394.0], [616.0, 269.0], [573.0, 185.0], [647.0, 188.0], [661.0, 221.0], [656.0, 231.0], [610.0, 187.0], [647.0, 176.0], [637.0201, 189.8183], [695.9799, 108.1817], [606.0, 217.0], [553.0, 161.0], [601.0, 167.0], [692.0, 185.0], [693.0, 240.0], [688.0, 313.0]], 'center': [594.0, 257.0], 'scale': 3.021046}\n",
      "First val annotation:  {'filename': '005808361.jpg', 'filepath': '/aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/images/005808361.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[804.0, 711.0], [816.0, 510.0], [908.0, 438.0], [1040.0, 454.0], [906.0, 528.0], [883.0, 707.0], [974.0, 446.0], [985.0, 253.0], [982.7591, 235.9694], [962.2409, 80.0306], [869.0, 214.0], [798.0, 340.0], [902.0, 253.0], [1067.0, 253.0], [1167.0, 353.0], [1142.0, 478.0]], 'center': [966.0, 340.0], 'scale': 4.718488}\n",
      "Start to build TF Records.\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0002_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0003_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0001_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0001_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0004_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0002_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0005_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0003_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0006_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0004_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0007_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0006_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0008_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0005_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0009_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0008_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0010_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0007_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0011_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0009_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0012_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0010_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0013_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0011_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0014_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0012_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0015_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0013_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0016_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0014_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0017_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0015_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0018_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0016_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0019_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0017_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0020_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0018_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0021_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0019_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0022_of_0064.tfrecords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0020_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0023_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0022_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0024_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0021_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0025_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0023_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0026_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0024_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0027_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0025_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0028_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0026_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0029_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0027_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0030_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0028_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0031_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0029_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0032_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0030_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m \n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0033_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0031_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0034_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0032_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0035_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0033_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0036_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0034_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0037_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0035_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0038_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0036_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0039_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0037_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0040_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0038_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0041_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0039_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0042_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0040_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0043_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0041_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0044_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0042_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0045_of_0064.tfrecords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0043_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0046_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0044_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0047_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0045_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0048_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0046_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0049_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0047_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0050_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0048_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0051_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0049_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0052_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0050_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0053_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0051_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0054_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0052_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0055_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0053_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0056_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0054_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0057_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0055_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0058_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0056_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0059_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0057_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0060_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0058_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0061_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0059_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0062_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0060_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0063_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0061_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0064_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0062_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0063_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/train_0064_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0001_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0002_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0003_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0001_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0004_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0002_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0005_of_0008.tfrecords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0003_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0006_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0004_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0007_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0005_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m start to build tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0008_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=695)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0006_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=693)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0007_of_0008.tfrecords\n",
      "Successfully wrote 25204 annotations to TF Records.\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=694)\u001b[0m finished building tf records for /aiffel/aiffel/2023-AIFFEL-QUEST/GoingDeeperQUEST08/data/tfrecords_mpii/val_0008_of_0008.tfrecords\n"
     ]
    }
   ],
   "source": [
    "num_train_shards = 64\n",
    "num_val_shards = 8\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "print('Start to parse annotations.')\n",
    "if not os.path.exists(TFRECORD_PATH):\n",
    "    os.makedirs(TFRECORD_PATH)\n",
    "\n",
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    train_annotations = [\n",
    "        parse_one_annotation(anno, IMAGE_PATH)\n",
    "        for anno in train_annos\n",
    "    ]\n",
    "    print('First train annotation: ', train_annotations[0])\n",
    "\n",
    "with open(VALID_JSON) as val_json:\n",
    "    val_annos = json.load(val_json)\n",
    "    val_annotations = [\n",
    "        parse_one_annotation(anno, IMAGE_PATH) \n",
    "        for anno in val_annos\n",
    "    ]\n",
    "    print('First val annotation: ', val_annotations[0])\n",
    "    \n",
    "print('Start to build TF Records.')\n",
    "build_tf_records(train_annotations, num_train_shards, 'train')\n",
    "build_tf_records(val_annotations, num_val_shards, 'val')\n",
    "\n",
    "print('Successfully wrote {} annotations to TF Records.'.format(\n",
    "    len(train_annotations) + len(val_annotations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb83f3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def parse_tfexample(example):\n",
    "    image_feature_description = {\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    return tf.io.parse_single_example(example, image_feature_description)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dee0f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def crop_roi(image, features, margin=0.2):\n",
    "    img_shape = tf.shape(image)\n",
    "    img_height = img_shape[0]\n",
    "    img_width = img_shape[1]\n",
    "    img_depth = img_shape[2]\n",
    "\n",
    "    keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "    keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "    center_x = features['image/object/center/x']\n",
    "    center_y = features['image/object/center/y']\n",
    "    body_height = features['image/object/scale'] * 200.0\n",
    "\n",
    "    # keypoint 중 유효한값(visible = 1) 만 사용합니다.\n",
    "    masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "    masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "\n",
    "    # min, max 값을 찾습니다.\n",
    "    keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "    keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "    keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "    keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "\n",
    "    # 높이 값을 이용해서 x, y 위치를 재조정 합니다. 박스를 정사각형으로 사용하기 위해 아래와 같이 사용합니다.\n",
    "    xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "\n",
    "    # 이미지 크기를 벗어나는 점을 재조정 해줍니다.\n",
    "    effective_xmin = xmin if xmin > 0 else 0\n",
    "    effective_ymin = ymin if ymin > 0 else 0\n",
    "    effective_xmax = xmax if xmax < img_width else img_width\n",
    "    effective_ymax = ymax if ymax < img_height else img_height\n",
    "    effective_height = effective_ymax - effective_ymin\n",
    "    effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "    image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "    new_shape = tf.shape(image)\n",
    "    new_height = new_shape[0]\n",
    "    new_width = new_shape[1]\n",
    "\n",
    "    effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "    effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "\n",
    "    return image, effective_keypoint_x, effective_keypoint_y\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "907d050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def generate_2d_guassian(height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "    heatmap = tf.zeros((height, width))\n",
    "\n",
    "    xmin = x0 - 3 * sigma\n",
    "    ymin = y0 - 3 * sigma\n",
    "    xmax = x0 + 3 * sigma\n",
    "    ymax = y0 + 3 * sigma\n",
    "    \n",
    "    if xmin >= width or ymin >= height or xmax < 0 or ymax < 0 or visibility == 0:\n",
    "        return heatmap\n",
    "\n",
    "    size = 6 * sigma + 1\n",
    "    x, y = tf.meshgrid(tf.range(0, 6 * sigma + 1, 1), tf.range(0, 6 * sigma + 1, 1), indexing='xy')\n",
    "\n",
    "    center_x = size // 2\n",
    "    center_y = size // 2\n",
    "\n",
    "    gaussian_patch = tf.cast(tf.math.exp(\n",
    "        -(tf.math.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale,\n",
    "                             dtype=tf.float32)\n",
    "\n",
    "    patch_xmin = tf.math.maximum(0, -xmin)\n",
    "    patch_ymin = tf.math.maximum(0, -ymin)\n",
    "    patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "    patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "    heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "    heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "    heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "    heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "    indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for j in tf.range(patch_ymin, patch_ymax):\n",
    "        for i in tf.range(patch_xmin, patch_xmax):\n",
    "            indices = indices.write(count, [heatmap_ymin + j, heatmap_xmin + i])\n",
    "            updates = updates.write(count, gaussian_patch[j][i])\n",
    "            count += 1\n",
    "\n",
    "    heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def make_heatmaps(features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "    v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "    x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "    y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "\n",
    "    num_heatmap = heatmap_shape[2]\n",
    "    heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "    for i in range(num_heatmap):\n",
    "        gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "        heatmap_array = heatmap_array.write(i, gaussian)\n",
    "\n",
    "    heatmaps = heatmap_array.stack()\n",
    "    heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0])  # change to (64, 64, 16)\n",
    "\n",
    "    return heatmaps\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "315dc730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class Preprocessor(object):\n",
    "    def __init__(self,\n",
    "                 image_shape=(256, 256, 3),\n",
    "                 heatmap_shape=(64, 64, 16),\n",
    "                 is_train=False):\n",
    "        self.is_train = is_train\n",
    "        self.image_shape = image_shape\n",
    "        self.heatmap_shape = heatmap_shape\n",
    "\n",
    "    def __call__(self, example):\n",
    "        features = self.parse_tfexample(example)\n",
    "        image = tf.io.decode_jpeg(features['image/encoded'])\n",
    "\n",
    "        if self.is_train:\n",
    "            random_margin = tf.random.uniform([1], 0.1, 0.3)[0]\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features, margin=random_margin)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "        else:\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "\n",
    "        image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "        heatmaps = self.make_heatmaps(features, keypoint_x, keypoint_y, self.heatmap_shape)\n",
    "\n",
    "        return image, heatmaps\n",
    "\n",
    "        \n",
    "    def crop_roi(self, image, features, margin=0.2):\n",
    "        img_shape = tf.shape(image)\n",
    "        img_height = img_shape[0]\n",
    "        img_width = img_shape[1]\n",
    "        img_depth = img_shape[2]\n",
    "\n",
    "        keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "        keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "        center_x = features['image/object/center/x']\n",
    "        center_y = features['image/object/center/y']\n",
    "        body_height = features['image/object/scale'] * 200.0\n",
    "        \n",
    "        masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "        masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "        \n",
    "        keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "        keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "        keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "        keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "        \n",
    "        xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        \n",
    "        effective_xmin = xmin if xmin > 0 else 0\n",
    "        effective_ymin = ymin if ymin > 0 else 0\n",
    "        effective_xmax = xmax if xmax < img_width else img_width\n",
    "        effective_ymax = ymax if ymax < img_height else img_height\n",
    "        effective_height = effective_ymax - effective_ymin\n",
    "        effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "        image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "        new_shape = tf.shape(image)\n",
    "        new_height = new_shape[0]\n",
    "        new_width = new_shape[1]\n",
    "        \n",
    "        effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "        effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "        \n",
    "        return image, effective_keypoint_x, effective_keypoint_y\n",
    "        \n",
    "    \n",
    "    def generate_2d_guassian(self, height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "        \n",
    "        heatmap = tf.zeros((height, width))\n",
    "\n",
    "        xmin = x0 - 3 * sigma\n",
    "        ymin = y0 - 3 * sigma\n",
    "        xmax = x0 + 3 * sigma\n",
    "        ymax = y0 + 3 * sigma\n",
    "\n",
    "        if xmin >= width or ymin >= height or xmax < 0 or ymax <0 or visibility == 0:\n",
    "            return heatmap\n",
    "\n",
    "        size = 6 * sigma + 1\n",
    "        x, y = tf.meshgrid(tf.range(0, 6*sigma+1, 1), tf.range(0, 6*sigma+1, 1), indexing='xy')\n",
    "\n",
    "        center_x = size // 2\n",
    "        center_y = size // 2\n",
    "\n",
    "        gaussian_patch = tf.cast(tf.math.exp(-(tf.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale, dtype=tf.float32)\n",
    "\n",
    "        patch_xmin = tf.math.maximum(0, -xmin)\n",
    "        patch_ymin = tf.math.maximum(0, -ymin)\n",
    "        patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "        patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "        heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "        heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "        heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "        heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "        indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "        updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for j in tf.range(patch_ymin, patch_ymax):\n",
    "            for i in tf.range(patch_xmin, patch_xmax):\n",
    "                indices = indices.write(count, [heatmap_ymin+j, heatmap_xmin+i])\n",
    "                updates = updates.write(count, gaussian_patch[j][i])\n",
    "                count += 1\n",
    "                \n",
    "        heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "        return heatmap\n",
    "\n",
    "\n",
    "    def make_heatmaps(self, features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "        v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "        x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "        y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "        \n",
    "        num_heatmap = heatmap_shape[2]\n",
    "        heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "        for i in range(num_heatmap):\n",
    "            gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "            heatmap_array = heatmap_array.write(i, gaussian)\n",
    "        \n",
    "        heatmaps = heatmap_array.stack()\n",
    "        heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0]) # change to (64, 64, 16)\n",
    "        \n",
    "        return heatmaps\n",
    "\n",
    "    def parse_tfexample(self, example):\n",
    "        image_feature_description = {\n",
    "            'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "            'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n",
    "        return tf.io.parse_single_example(example,\n",
    "                                          image_feature_description)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0429267",
   "metadata": {},
   "source": [
    "- Hourglass 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c8d7129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def BottleneckBlock(inputs, filters, strides=1, downsample=False, name=None):\n",
    "    identity = inputs\n",
    "    if downsample:\n",
    "        identity = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(inputs)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=3,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = Add()([identity, x])\n",
    "    return x\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1d78f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def HourglassModule(inputs, order, filters, num_residual):\n",
    "    \n",
    "    up1 = BottleneckBlock(inputs, filters, downsample=False)\n",
    "    for i in range(num_residual):\n",
    "        up1 = BottleneckBlock(up1, filters, downsample=False)\n",
    "\n",
    "    low1 = MaxPool2D(pool_size=2, strides=2)(inputs)\n",
    "    for i in range(num_residual):\n",
    "        low1 = BottleneckBlock(low1, filters, downsample=False)\n",
    "\n",
    "    low2 = low1\n",
    "    if order > 1:\n",
    "        low2 = HourglassModule(low1, order - 1, filters, num_residual)\n",
    "    else:\n",
    "        for i in range(num_residual):\n",
    "            low2 = BottleneckBlock(low2, filters, downsample=False)\n",
    "\n",
    "    low3 = low2\n",
    "    for i in range(num_residual):\n",
    "        low3 = BottleneckBlock(low3, filters, downsample=False)\n",
    "\n",
    "    up2 = UpSampling2D(size=2)(low3)\n",
    "\n",
    "    return up2 + up1\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "183c4849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def LinearLayer(inputs, filters):\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42674954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def StackedHourglassNetwork(\n",
    "        input_shape=(256, 256, 3), \n",
    "        num_stack=4, \n",
    "        num_residual=1,\n",
    "        num_heatmap=16):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=7,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=True)\n",
    "    x = MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=False)\n",
    "    x = BottleneckBlock(x, 256, downsample=True)\n",
    "\n",
    "    ys = []\n",
    "    for i in range(num_stack):\n",
    "        x = HourglassModule(x, order=4, filters=256, num_residual=num_residual)\n",
    "        for i in range(num_residual):\n",
    "            x = BottleneckBlock(x, 256, downsample=False)\n",
    "\n",
    "        x = LinearLayer(x, 256)\n",
    "\n",
    "        y = Conv2D(\n",
    "            filters=num_heatmap,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if i < num_stack - 1:\n",
    "            y_intermediate_1 = Conv2D(filters=256, kernel_size=1, strides=1)(x)\n",
    "            y_intermediate_2 = Conv2D(filters=256, kernel_size=1, strides=1)(y)\n",
    "            x = Add()([y_intermediate_1, y_intermediate_2])\n",
    "\n",
    "    return tf.keras.Model(inputs, ys, name='stacked_hourglass')\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c9a8c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 epochs,\n",
    "                 global_batch_size,\n",
    "                 strategy,\n",
    "                 initial_learning_rate):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.strategy = strategy\n",
    "        self.global_batch_size = global_batch_size\n",
    "        self.loss_object = tf.keras.losses.MeanSquaredError(\n",
    "            reduction=tf.keras.losses.Reduction.NONE)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=initial_learning_rate)\n",
    "        self.model = model\n",
    "\n",
    "        self.current_learning_rate = initial_learning_rate\n",
    "        self.last_val_loss = math.inf\n",
    "        self.lowest_val_loss = math.inf\n",
    "        self.patience_count = 0\n",
    "        self.max_patience = 10\n",
    "        self.best_model = None\n",
    "\n",
    "    def lr_decay(self):\n",
    "        if self.patience_count >= self.max_patience:\n",
    "            self.current_learning_rate /= 10.0\n",
    "            self.patience_count = 0\n",
    "        elif self.last_val_loss == self.lowest_val_loss:\n",
    "            self.patience_count = 0\n",
    "        self.patience_count += 1\n",
    "\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def lr_decay_step(self, epoch):\n",
    "        if epoch == 25 or epoch == 50 or epoch == 75:\n",
    "            self.current_learning_rate /= 10.0\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def compute_loss(self, labels, outputs):\n",
    "        loss = 0\n",
    "        for output in outputs:\n",
    "            weights = tf.cast(labels > 0, dtype=tf.float32) * 81 + 1\n",
    "            loss += tf.math.reduce_mean(\n",
    "                tf.math.square(labels - output) * weights) * (\n",
    "                    1. / self.global_batch_size)\n",
    "        return loss\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self.model(images, training=True)\n",
    "            loss = self.compute_loss(labels, outputs)\n",
    "\n",
    "        grads = tape.gradient(\n",
    "            target=loss, sources=self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def val_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        outputs = self.model(images, training=False)\n",
    "        loss = self.compute_loss(labels, outputs)\n",
    "        return loss\n",
    "\n",
    "    def run(self, train_dist_dataset, val_dist_dataset):\n",
    "        @tf.function\n",
    "        def distributed_train_epoch(dataset):\n",
    "            tf.print('Start distributed traininng...')\n",
    "            total_loss = 0.0\n",
    "            num_train_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.train_step, args=(one_batch, ))\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                total_loss += batch_loss\n",
    "                num_train_batches += 1\n",
    "                tf.print('Trained batch', num_train_batches, 'batch loss',\n",
    "                         batch_loss, 'epoch total loss', total_loss / num_train_batches)\n",
    "            return total_loss, num_train_batches\n",
    "\n",
    "        @tf.function\n",
    "        def distributed_val_epoch(dataset):\n",
    "            total_loss = 0.0\n",
    "            num_val_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.val_step, args=(one_batch, ))\n",
    "                num_val_batches += 1\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                tf.print('Validated batch', num_val_batches, 'batch loss',\n",
    "                         batch_loss)\n",
    "                if not tf.math.is_nan(batch_loss):\n",
    "                    # TODO: Find out why the last validation batch loss become NaN\n",
    "                    total_loss += batch_loss\n",
    "                else:\n",
    "                    num_val_batches -= 1\n",
    "\n",
    "            return total_loss, num_val_batches\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            self.lr_decay()\n",
    "            print('Start epoch {} with learning rate {}'.format(\n",
    "                epoch, self.current_learning_rate))\n",
    "\n",
    "            train_total_loss, num_train_batches = distributed_train_epoch(\n",
    "                train_dist_dataset)\n",
    "            train_loss = train_total_loss / num_train_batches\n",
    "            print('Epoch {} train loss {}'.format(epoch, train_loss))\n",
    "\n",
    "            val_total_loss, num_val_batches = distributed_val_epoch(\n",
    "                val_dist_dataset)\n",
    "            val_loss = val_total_loss / num_val_batches\n",
    "            print('Epoch {} val loss {}'.format(epoch, val_loss))\n",
    "\n",
    "            # save model when reach a new lowest validation loss\n",
    "            if val_loss < self.lowest_val_loss:\n",
    "                self.save_model(epoch, val_loss)\n",
    "                self.lowest_val_loss = val_loss\n",
    "            self.last_val_loss = val_loss\n",
    "\n",
    "        return self.best_model\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        model_name = MODEL_PATH + '/model-epoch-{}-loss-{:.4f}.h5'.format(epoch, loss)\n",
    "        self.model.save_weights(model_name)\n",
    "        self.best_model = model_name\n",
    "        print(\"Model {} saved.\".format(model_name))\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "069af196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "HEATMAP_SIZE = (64, 64)\n",
    "\n",
    "def create_dataset(tfrecords, batch_size, num_heatmap, is_train):\n",
    "    preprocess = Preprocessor(\n",
    "        IMAGE_SHAPE, (HEATMAP_SIZE[0], HEATMAP_SIZE[1], num_heatmap), is_train)\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(tfrecords)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61e9b4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def train(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    global_batch_size = strategy.num_replicas_in_sync * batch_size\n",
    "    train_dataset = create_dataset(\n",
    "        train_tfrecords, global_batch_size, num_heatmap, is_train=True)\n",
    "    val_dataset = create_dataset(\n",
    "        val_tfrecords, global_batch_size, num_heatmap, is_train=False)\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "\n",
    "    with strategy.scope():\n",
    "        train_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            train_dataset)\n",
    "        val_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            val_dataset)\n",
    "\n",
    "        model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1, num_heatmap)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            epochs,\n",
    "            global_batch_size,\n",
    "            strategy,\n",
    "            initial_learning_rate=learning_rate)\n",
    "\n",
    "        print('Start training...')\n",
    "        return trainer.run(train_dist_dataset, val_dist_dataset)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac9412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Start training...\n",
      "Start epoch 1 with learning rate 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:374: UserWarning: To make it possible to preserve tf.data options across serialization boundaries, their implementation has moved to be part of the TensorFlow graph. As a consequence, the options value is in general no longer known at graph construction time. Invoking this method in graph mode retains the legacy behavior of the original implementation, but note that the returned value might not reflect the actual value of the options.\n",
      "  warnings.warn(\"To make it possible to preserve tf.data options across \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 2.9627471 epoch total loss 2.9627471\n",
      "Trained batch 2 batch loss 2.7037921 epoch total loss 2.8332696\n",
      "Trained batch 3 batch loss 2.57097554 epoch total loss 2.74583817\n",
      "Trained batch 4 batch loss 2.56658173 epoch total loss 2.70102406\n",
      "Trained batch 5 batch loss 2.49242592 epoch total loss 2.65930438\n",
      "Trained batch 6 batch loss 2.39616776 epoch total loss 2.61544824\n",
      "Trained batch 7 batch loss 2.31056333 epoch total loss 2.57189345\n",
      "Trained batch 8 batch loss 2.26147223 epoch total loss 2.53309083\n",
      "Trained batch 9 batch loss 2.31674123 epoch total loss 2.50905204\n",
      "Trained batch 10 batch loss 2.13955975 epoch total loss 2.47210264\n",
      "Trained batch 11 batch loss 2.19709682 epoch total loss 2.44710231\n",
      "Trained batch 12 batch loss 2.15435171 epoch total loss 2.42270637\n",
      "Trained batch 13 batch loss 2.18863 epoch total loss 2.40470076\n",
      "Trained batch 14 batch loss 2.03829074 epoch total loss 2.37852859\n",
      "Trained batch 15 batch loss 2.10087395 epoch total loss 2.36001849\n",
      "Trained batch 16 batch loss 2.10010624 epoch total loss 2.34377384\n",
      "Trained batch 17 batch loss 2.1286726 epoch total loss 2.33112097\n",
      "Trained batch 18 batch loss 2.05499125 epoch total loss 2.3157804\n",
      "Trained batch 19 batch loss 1.97395086 epoch total loss 2.29778934\n",
      "Trained batch 20 batch loss 2.00036621 epoch total loss 2.28291821\n",
      "Trained batch 21 batch loss 2.03767896 epoch total loss 2.27124\n",
      "Trained batch 22 batch loss 1.99939251 epoch total loss 2.25888348\n",
      "Trained batch 23 batch loss 1.9372493 epoch total loss 2.24489927\n",
      "Trained batch 24 batch loss 1.86538589 epoch total loss 2.22908616\n",
      "Trained batch 25 batch loss 1.84496617 epoch total loss 2.21372151\n",
      "Trained batch 26 batch loss 1.91136479 epoch total loss 2.20209241\n",
      "Trained batch 27 batch loss 1.94123304 epoch total loss 2.19243097\n",
      "Trained batch 28 batch loss 1.95585263 epoch total loss 2.18398166\n",
      "Trained batch 29 batch loss 1.92522848 epoch total loss 2.17505932\n",
      "Trained batch 30 batch loss 1.93555164 epoch total loss 2.16707563\n",
      "Trained batch 31 batch loss 1.76447165 epoch total loss 2.1540885\n",
      "Trained batch 32 batch loss 1.8993293 epoch total loss 2.14612722\n",
      "Trained batch 33 batch loss 1.84489667 epoch total loss 2.13699889\n",
      "Trained batch 34 batch loss 1.68771434 epoch total loss 2.12378478\n",
      "Trained batch 35 batch loss 1.517802 epoch total loss 2.10647082\n",
      "Trained batch 36 batch loss 1.70152545 epoch total loss 2.09522223\n",
      "Trained batch 37 batch loss 1.74017441 epoch total loss 2.08562636\n",
      "Trained batch 38 batch loss 1.78413582 epoch total loss 2.07769227\n",
      "Trained batch 39 batch loss 1.84308815 epoch total loss 2.07167673\n",
      "Trained batch 40 batch loss 1.76433957 epoch total loss 2.06399345\n",
      "Trained batch 41 batch loss 1.60664725 epoch total loss 2.05283856\n",
      "Trained batch 42 batch loss 1.74948764 epoch total loss 2.04561591\n",
      "Trained batch 43 batch loss 1.80296469 epoch total loss 2.03997278\n",
      "Trained batch 44 batch loss 1.56499875 epoch total loss 2.02917814\n",
      "Trained batch 45 batch loss 1.60614026 epoch total loss 2.0197773\n",
      "Trained batch 46 batch loss 1.84187388 epoch total loss 2.01590967\n",
      "Trained batch 47 batch loss 1.82750535 epoch total loss 2.01190114\n",
      "Trained batch 48 batch loss 1.84607387 epoch total loss 2.00844646\n",
      "Trained batch 49 batch loss 1.76074255 epoch total loss 2.00339127\n",
      "Trained batch 50 batch loss 1.6999768 epoch total loss 1.99732304\n",
      "Trained batch 51 batch loss 1.68440056 epoch total loss 1.99118733\n",
      "Trained batch 52 batch loss 1.69872117 epoch total loss 1.98556304\n",
      "Trained batch 53 batch loss 1.69007957 epoch total loss 1.97998786\n",
      "Trained batch 54 batch loss 1.68176043 epoch total loss 1.97446513\n",
      "Trained batch 55 batch loss 1.650877 epoch total loss 1.9685818\n",
      "Trained batch 56 batch loss 1.57378912 epoch total loss 1.96153188\n",
      "Trained batch 57 batch loss 1.57119334 epoch total loss 1.95468378\n",
      "Trained batch 58 batch loss 1.62242103 epoch total loss 1.94895518\n",
      "Trained batch 59 batch loss 1.72816896 epoch total loss 1.94521308\n",
      "Trained batch 60 batch loss 1.71437275 epoch total loss 1.94136572\n",
      "Trained batch 61 batch loss 1.67480063 epoch total loss 1.93699574\n",
      "Trained batch 62 batch loss 1.77812696 epoch total loss 1.93443334\n",
      "Trained batch 63 batch loss 1.80052936 epoch total loss 1.93230784\n",
      "Trained batch 64 batch loss 1.74904442 epoch total loss 1.92944443\n",
      "Trained batch 65 batch loss 1.73746729 epoch total loss 1.9264909\n",
      "Trained batch 66 batch loss 1.81789589 epoch total loss 1.92484546\n",
      "Trained batch 67 batch loss 1.72392583 epoch total loss 1.92184675\n",
      "Trained batch 68 batch loss 1.76886165 epoch total loss 1.91959691\n",
      "Trained batch 69 batch loss 1.80419624 epoch total loss 1.91792452\n",
      "Trained batch 70 batch loss 1.70969486 epoch total loss 1.91494989\n",
      "Trained batch 71 batch loss 1.71450615 epoch total loss 1.91212678\n",
      "Trained batch 72 batch loss 1.78881526 epoch total loss 1.91041422\n",
      "Trained batch 73 batch loss 1.80800545 epoch total loss 1.90901124\n",
      "Trained batch 74 batch loss 1.75866926 epoch total loss 1.90697956\n",
      "Trained batch 75 batch loss 1.80667508 epoch total loss 1.90564203\n",
      "Trained batch 76 batch loss 1.78994036 epoch total loss 1.90411985\n",
      "Trained batch 77 batch loss 1.79865456 epoch total loss 1.90275013\n",
      "Trained batch 78 batch loss 1.8377068 epoch total loss 1.90191627\n",
      "Trained batch 79 batch loss 1.81518924 epoch total loss 1.90081847\n",
      "Trained batch 80 batch loss 1.81015944 epoch total loss 1.89968526\n",
      "Trained batch 81 batch loss 1.78825104 epoch total loss 1.89830959\n",
      "Trained batch 82 batch loss 1.76492345 epoch total loss 1.89668298\n",
      "Trained batch 83 batch loss 1.73274481 epoch total loss 1.89470768\n",
      "Trained batch 84 batch loss 1.71560824 epoch total loss 1.89257562\n",
      "Trained batch 85 batch loss 1.75919306 epoch total loss 1.89100623\n",
      "Trained batch 86 batch loss 1.69465947 epoch total loss 1.88872313\n",
      "Trained batch 87 batch loss 1.79678977 epoch total loss 1.88766634\n",
      "Trained batch 88 batch loss 1.70398402 epoch total loss 1.88557899\n",
      "Trained batch 89 batch loss 1.68552518 epoch total loss 1.8833313\n",
      "Trained batch 90 batch loss 1.69982743 epoch total loss 1.88129234\n",
      "Trained batch 91 batch loss 1.52084887 epoch total loss 1.87733138\n",
      "Trained batch 92 batch loss 1.60440373 epoch total loss 1.87436473\n",
      "Trained batch 93 batch loss 1.68391109 epoch total loss 1.87231696\n",
      "Trained batch 94 batch loss 1.76263618 epoch total loss 1.87115014\n",
      "Trained batch 95 batch loss 1.77241218 epoch total loss 1.87011075\n",
      "Trained batch 96 batch loss 1.7056694 epoch total loss 1.86839783\n",
      "Trained batch 97 batch loss 1.73204851 epoch total loss 1.86699224\n",
      "Trained batch 98 batch loss 1.64177072 epoch total loss 1.86469412\n",
      "Trained batch 99 batch loss 1.6639781 epoch total loss 1.86266661\n",
      "Trained batch 100 batch loss 1.58945918 epoch total loss 1.85993457\n",
      "Trained batch 101 batch loss 1.61009073 epoch total loss 1.85746086\n",
      "Trained batch 102 batch loss 1.74446738 epoch total loss 1.85635304\n",
      "Trained batch 103 batch loss 1.70778406 epoch total loss 1.85491049\n",
      "Trained batch 104 batch loss 1.83375883 epoch total loss 1.85470712\n",
      "Trained batch 105 batch loss 1.83025253 epoch total loss 1.85447419\n",
      "Trained batch 106 batch loss 1.79289639 epoch total loss 1.85389316\n",
      "Trained batch 107 batch loss 1.7498765 epoch total loss 1.85292113\n",
      "Trained batch 108 batch loss 1.6760422 epoch total loss 1.85128331\n",
      "Trained batch 109 batch loss 1.67588639 epoch total loss 1.84967422\n",
      "Trained batch 110 batch loss 1.67509735 epoch total loss 1.84808707\n",
      "Trained batch 111 batch loss 1.75910401 epoch total loss 1.84728551\n",
      "Trained batch 112 batch loss 1.60884726 epoch total loss 1.84515655\n",
      "Trained batch 113 batch loss 1.68549216 epoch total loss 1.84374356\n",
      "Trained batch 114 batch loss 1.69439971 epoch total loss 1.84243345\n",
      "Trained batch 115 batch loss 1.63448358 epoch total loss 1.84062529\n",
      "Trained batch 116 batch loss 1.64622974 epoch total loss 1.83894944\n",
      "Trained batch 117 batch loss 1.67695451 epoch total loss 1.83756483\n",
      "Trained batch 118 batch loss 1.61706674 epoch total loss 1.83569622\n",
      "Trained batch 119 batch loss 1.73018789 epoch total loss 1.83480966\n",
      "Trained batch 120 batch loss 1.66860032 epoch total loss 1.83342445\n",
      "Trained batch 121 batch loss 1.7051518 epoch total loss 1.83236444\n",
      "Trained batch 122 batch loss 1.61767268 epoch total loss 1.83060467\n",
      "Trained batch 123 batch loss 1.76155174 epoch total loss 1.83004332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 124 batch loss 1.69750237 epoch total loss 1.82897449\n",
      "Trained batch 125 batch loss 1.67511475 epoch total loss 1.82774353\n",
      "Trained batch 126 batch loss 1.70673919 epoch total loss 1.82678318\n",
      "Trained batch 127 batch loss 1.66058612 epoch total loss 1.8254745\n",
      "Trained batch 128 batch loss 1.70961356 epoch total loss 1.82456934\n",
      "Trained batch 129 batch loss 1.44889235 epoch total loss 1.82165718\n",
      "Trained batch 130 batch loss 1.67573428 epoch total loss 1.82053471\n",
      "Trained batch 131 batch loss 1.68310213 epoch total loss 1.81948566\n",
      "Trained batch 132 batch loss 1.64962709 epoch total loss 1.8181988\n",
      "Trained batch 133 batch loss 1.63596606 epoch total loss 1.81682873\n",
      "Trained batch 134 batch loss 1.66609728 epoch total loss 1.81570375\n",
      "Trained batch 135 batch loss 1.71309423 epoch total loss 1.81494367\n",
      "Trained batch 136 batch loss 1.65274096 epoch total loss 1.81375098\n",
      "Trained batch 137 batch loss 1.70787358 epoch total loss 1.81297815\n",
      "Trained batch 138 batch loss 1.64944136 epoch total loss 1.81179309\n",
      "Trained batch 139 batch loss 1.51867664 epoch total loss 1.8096844\n",
      "Trained batch 140 batch loss 1.60656345 epoch total loss 1.8082335\n",
      "Trained batch 141 batch loss 1.69304156 epoch total loss 1.80741656\n",
      "Trained batch 142 batch loss 1.71357453 epoch total loss 1.80675566\n",
      "Trained batch 143 batch loss 1.73883355 epoch total loss 1.80628061\n",
      "Trained batch 144 batch loss 1.78840637 epoch total loss 1.80615664\n",
      "Trained batch 145 batch loss 1.74704027 epoch total loss 1.80574894\n",
      "Trained batch 146 batch loss 1.74075305 epoch total loss 1.80530369\n",
      "Trained batch 147 batch loss 1.73086929 epoch total loss 1.80479729\n",
      "Trained batch 148 batch loss 1.54046679 epoch total loss 1.8030113\n",
      "Trained batch 149 batch loss 1.42058301 epoch total loss 1.80044472\n",
      "Trained batch 150 batch loss 1.38807154 epoch total loss 1.79769552\n",
      "Trained batch 151 batch loss 1.38653064 epoch total loss 1.79497266\n",
      "Trained batch 152 batch loss 1.4669292 epoch total loss 1.79281437\n",
      "Trained batch 153 batch loss 1.39015651 epoch total loss 1.79018271\n",
      "Trained batch 154 batch loss 1.51085925 epoch total loss 1.78836894\n",
      "Trained batch 155 batch loss 1.72536623 epoch total loss 1.78796244\n",
      "Trained batch 156 batch loss 1.6578753 epoch total loss 1.78712857\n",
      "Trained batch 157 batch loss 1.73351789 epoch total loss 1.78678715\n",
      "Trained batch 158 batch loss 1.7428087 epoch total loss 1.78650868\n",
      "Trained batch 159 batch loss 1.73904991 epoch total loss 1.78621018\n",
      "Trained batch 160 batch loss 1.75948143 epoch total loss 1.78604317\n",
      "Trained batch 161 batch loss 1.73676121 epoch total loss 1.78573704\n",
      "Trained batch 162 batch loss 1.72896552 epoch total loss 1.78538668\n",
      "Trained batch 163 batch loss 1.73443496 epoch total loss 1.78507411\n",
      "Trained batch 164 batch loss 1.69960797 epoch total loss 1.78455293\n",
      "Trained batch 165 batch loss 1.67792928 epoch total loss 1.7839067\n",
      "Trained batch 166 batch loss 1.57611394 epoch total loss 1.78265488\n",
      "Trained batch 167 batch loss 1.50625443 epoch total loss 1.78099978\n",
      "Trained batch 168 batch loss 1.5689795 epoch total loss 1.77973771\n",
      "Trained batch 169 batch loss 1.71570289 epoch total loss 1.77935886\n",
      "Trained batch 170 batch loss 1.53268218 epoch total loss 1.77790773\n",
      "Trained batch 171 batch loss 1.6890676 epoch total loss 1.77738822\n",
      "Trained batch 172 batch loss 1.66178191 epoch total loss 1.77671599\n",
      "Trained batch 173 batch loss 1.60886395 epoch total loss 1.77574575\n",
      "Trained batch 174 batch loss 1.4006443 epoch total loss 1.77359\n",
      "Trained batch 175 batch loss 1.36905646 epoch total loss 1.77127826\n",
      "Trained batch 176 batch loss 1.41760314 epoch total loss 1.76926875\n",
      "Trained batch 177 batch loss 1.56600356 epoch total loss 1.76812041\n",
      "Trained batch 178 batch loss 1.69310355 epoch total loss 1.767699\n",
      "Trained batch 179 batch loss 1.79680252 epoch total loss 1.7678616\n",
      "Trained batch 180 batch loss 1.61666214 epoch total loss 1.76702166\n",
      "Trained batch 181 batch loss 1.51831818 epoch total loss 1.76564765\n",
      "Trained batch 182 batch loss 1.62701654 epoch total loss 1.7648859\n",
      "Trained batch 183 batch loss 1.74189281 epoch total loss 1.76476014\n",
      "Trained batch 184 batch loss 1.76255345 epoch total loss 1.7647481\n",
      "Trained batch 185 batch loss 1.71984303 epoch total loss 1.76450539\n",
      "Trained batch 186 batch loss 1.69054365 epoch total loss 1.76410782\n",
      "Trained batch 187 batch loss 1.71908236 epoch total loss 1.76386702\n",
      "Trained batch 188 batch loss 1.67041862 epoch total loss 1.76336992\n",
      "Trained batch 189 batch loss 1.73560357 epoch total loss 1.76322293\n",
      "Trained batch 190 batch loss 1.58260953 epoch total loss 1.76227236\n",
      "Trained batch 191 batch loss 1.6627717 epoch total loss 1.76175153\n",
      "Trained batch 192 batch loss 1.68309057 epoch total loss 1.76134193\n",
      "Trained batch 193 batch loss 1.62113369 epoch total loss 1.76061535\n",
      "Trained batch 194 batch loss 1.5547235 epoch total loss 1.75955403\n",
      "Trained batch 195 batch loss 1.52018332 epoch total loss 1.75832641\n",
      "Trained batch 196 batch loss 1.65002394 epoch total loss 1.75777388\n",
      "Trained batch 197 batch loss 1.63294053 epoch total loss 1.75714016\n",
      "Trained batch 198 batch loss 1.58676755 epoch total loss 1.75627971\n",
      "Trained batch 199 batch loss 1.64599776 epoch total loss 1.7557255\n",
      "Trained batch 200 batch loss 1.62464213 epoch total loss 1.75507009\n",
      "Trained batch 201 batch loss 1.63163161 epoch total loss 1.75445592\n",
      "Trained batch 202 batch loss 1.65390146 epoch total loss 1.75395811\n",
      "Trained batch 203 batch loss 1.56122136 epoch total loss 1.7530086\n",
      "Trained batch 204 batch loss 1.60270381 epoch total loss 1.75227177\n",
      "Trained batch 205 batch loss 1.69401717 epoch total loss 1.7519877\n",
      "Trained batch 206 batch loss 1.72894609 epoch total loss 1.75187576\n",
      "Trained batch 207 batch loss 1.70437622 epoch total loss 1.75164628\n",
      "Trained batch 208 batch loss 1.72052085 epoch total loss 1.75149667\n",
      "Trained batch 209 batch loss 1.72026455 epoch total loss 1.7513473\n",
      "Trained batch 210 batch loss 1.74105132 epoch total loss 1.75129831\n",
      "Trained batch 211 batch loss 1.65032148 epoch total loss 1.7508198\n",
      "Trained batch 212 batch loss 1.65785134 epoch total loss 1.75038123\n",
      "Trained batch 213 batch loss 1.73350739 epoch total loss 1.75030208\n",
      "Trained batch 214 batch loss 1.71066344 epoch total loss 1.75011683\n",
      "Trained batch 215 batch loss 1.70400643 epoch total loss 1.74990237\n",
      "Trained batch 216 batch loss 1.6777904 epoch total loss 1.74956846\n",
      "Trained batch 217 batch loss 1.65044236 epoch total loss 1.74911177\n",
      "Trained batch 218 batch loss 1.65668464 epoch total loss 1.74868774\n",
      "Trained batch 219 batch loss 1.57078838 epoch total loss 1.74787545\n",
      "Trained batch 220 batch loss 1.4894743 epoch total loss 1.74670088\n",
      "Trained batch 221 batch loss 1.42297637 epoch total loss 1.74523604\n",
      "Trained batch 222 batch loss 1.66749835 epoch total loss 1.74488592\n",
      "Trained batch 223 batch loss 1.4738282 epoch total loss 1.74367046\n",
      "Trained batch 224 batch loss 1.55685759 epoch total loss 1.74283636\n",
      "Trained batch 225 batch loss 1.55752444 epoch total loss 1.74201286\n",
      "Trained batch 226 batch loss 1.57721341 epoch total loss 1.74128354\n",
      "Trained batch 227 batch loss 1.58929884 epoch total loss 1.74061406\n",
      "Trained batch 228 batch loss 1.65081024 epoch total loss 1.74022019\n",
      "Trained batch 229 batch loss 1.54996192 epoch total loss 1.7393893\n",
      "Trained batch 230 batch loss 1.66500056 epoch total loss 1.739066\n",
      "Trained batch 231 batch loss 1.66835022 epoch total loss 1.73875976\n",
      "Trained batch 232 batch loss 1.34838963 epoch total loss 1.73707712\n",
      "Trained batch 233 batch loss 1.30904448 epoch total loss 1.7352401\n",
      "Trained batch 234 batch loss 1.36229753 epoch total loss 1.73364639\n",
      "Trained batch 235 batch loss 1.67243993 epoch total loss 1.73338592\n",
      "Trained batch 236 batch loss 1.62861991 epoch total loss 1.7329421\n",
      "Trained batch 237 batch loss 1.72761333 epoch total loss 1.73291957\n",
      "Trained batch 238 batch loss 1.66749239 epoch total loss 1.73264456\n",
      "Trained batch 239 batch loss 1.64858007 epoch total loss 1.73229289\n",
      "Trained batch 240 batch loss 1.60725307 epoch total loss 1.73177183\n",
      "Trained batch 241 batch loss 1.56733453 epoch total loss 1.73108947\n",
      "Trained batch 242 batch loss 1.64236307 epoch total loss 1.7307229\n",
      "Trained batch 243 batch loss 1.63327932 epoch total loss 1.73032176\n",
      "Trained batch 244 batch loss 1.51133931 epoch total loss 1.72942436\n",
      "Trained batch 245 batch loss 1.58782363 epoch total loss 1.72884643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 246 batch loss 1.50282085 epoch total loss 1.72792757\n",
      "Trained batch 247 batch loss 1.62952769 epoch total loss 1.72752917\n",
      "Trained batch 248 batch loss 1.6481216 epoch total loss 1.72720897\n",
      "Trained batch 249 batch loss 1.61837721 epoch total loss 1.72677195\n",
      "Trained batch 250 batch loss 1.63381779 epoch total loss 1.72640014\n",
      "Trained batch 251 batch loss 1.58273709 epoch total loss 1.72582781\n",
      "Trained batch 252 batch loss 1.53521991 epoch total loss 1.72507143\n",
      "Trained batch 253 batch loss 1.63122892 epoch total loss 1.72470045\n",
      "Trained batch 254 batch loss 1.62569904 epoch total loss 1.72431064\n",
      "Trained batch 255 batch loss 1.64195383 epoch total loss 1.72398782\n",
      "Trained batch 256 batch loss 1.7070744 epoch total loss 1.72392166\n",
      "Trained batch 257 batch loss 1.65185082 epoch total loss 1.72364128\n",
      "Trained batch 258 batch loss 1.53345931 epoch total loss 1.72290409\n",
      "Trained batch 259 batch loss 1.60172868 epoch total loss 1.72243619\n",
      "Trained batch 260 batch loss 1.62157667 epoch total loss 1.72204828\n",
      "Trained batch 261 batch loss 1.67263865 epoch total loss 1.72185898\n",
      "Trained batch 262 batch loss 1.56835842 epoch total loss 1.72127306\n",
      "Trained batch 263 batch loss 1.62904501 epoch total loss 1.72092247\n",
      "Trained batch 264 batch loss 1.53332984 epoch total loss 1.72021186\n",
      "Trained batch 265 batch loss 1.66197634 epoch total loss 1.71999216\n",
      "Trained batch 266 batch loss 1.6657083 epoch total loss 1.71978807\n",
      "Trained batch 267 batch loss 1.57225311 epoch total loss 1.71923554\n",
      "Trained batch 268 batch loss 1.60435534 epoch total loss 1.71880698\n",
      "Trained batch 269 batch loss 1.56563973 epoch total loss 1.71823752\n",
      "Trained batch 270 batch loss 1.60521555 epoch total loss 1.71781898\n",
      "Trained batch 271 batch loss 1.64071178 epoch total loss 1.71753442\n",
      "Trained batch 272 batch loss 1.6075201 epoch total loss 1.71713\n",
      "Trained batch 273 batch loss 1.58835912 epoch total loss 1.71665823\n",
      "Trained batch 274 batch loss 1.61791432 epoch total loss 1.71629786\n",
      "Trained batch 275 batch loss 1.59644079 epoch total loss 1.71586204\n",
      "Trained batch 276 batch loss 1.71677268 epoch total loss 1.71586537\n",
      "Trained batch 277 batch loss 1.68274927 epoch total loss 1.71574569\n",
      "Trained batch 278 batch loss 1.65135717 epoch total loss 1.71551418\n",
      "Trained batch 279 batch loss 1.57958 epoch total loss 1.71502697\n",
      "Trained batch 280 batch loss 1.69604683 epoch total loss 1.71495914\n",
      "Trained batch 281 batch loss 1.67909193 epoch total loss 1.71483147\n",
      "Trained batch 282 batch loss 1.66499949 epoch total loss 1.7146548\n",
      "Trained batch 283 batch loss 1.65616536 epoch total loss 1.71444809\n",
      "Trained batch 284 batch loss 1.59277439 epoch total loss 1.71401966\n",
      "Trained batch 285 batch loss 1.5362891 epoch total loss 1.71339607\n",
      "Trained batch 286 batch loss 1.51492 epoch total loss 1.71270204\n",
      "Trained batch 287 batch loss 1.64630687 epoch total loss 1.71247077\n",
      "Trained batch 288 batch loss 1.71031499 epoch total loss 1.71246326\n",
      "Trained batch 289 batch loss 1.6770941 epoch total loss 1.71234083\n",
      "Trained batch 290 batch loss 1.7878592 epoch total loss 1.7126013\n",
      "Trained batch 291 batch loss 1.69725847 epoch total loss 1.71254861\n",
      "Trained batch 292 batch loss 1.5971694 epoch total loss 1.71215355\n",
      "Trained batch 293 batch loss 1.65858138 epoch total loss 1.71197057\n",
      "Trained batch 294 batch loss 1.62260365 epoch total loss 1.71166658\n",
      "Trained batch 295 batch loss 1.57265282 epoch total loss 1.71119535\n",
      "Trained batch 296 batch loss 1.63569713 epoch total loss 1.71094036\n"
     ]
    }
   ],
   "source": [
    "train_tfrecords = os.path.join(TFRECORD_PATH, 'train*')\n",
    "val_tfrecords = os.path.join(TFRECORD_PATH, 'val*')\n",
    "epochs = 2\n",
    "batch_size = 16\n",
    "num_heatmap = 16\n",
    "learning_rate = 0.0007\n",
    "\n",
    "best_model_file = train(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc31b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = os.path.join(PROJECT_PATH, 'models', 'model-v0.0.1-epoch-2-loss-1.3072.h5')\n",
    "\n",
    "model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1)\n",
    "model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "# 이전의 학습하는 코드 블럭을 통해 학습하고 그 모델을 사용할 경우 아래 주석 처리된 코드를 사용하면 됩니다\n",
    "# model.load_weights(best_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93423898",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ANKLE = 0\n",
    "R_KNEE = 1\n",
    "R_HIP = 2\n",
    "L_HIP = 3\n",
    "L_KNEE = 4\n",
    "L_ANKLE = 5\n",
    "PELVIS = 6\n",
    "THORAX = 7\n",
    "UPPER_NECK = 8\n",
    "HEAD_TOP = 9\n",
    "R_WRIST = 10\n",
    "R_ELBOW = 11\n",
    "R_SHOULDER = 12\n",
    "L_SHOULDER = 13\n",
    "L_ELBOW = 14\n",
    "L_WRIST = 15\n",
    "\n",
    "MPII_BONES = [\n",
    "    [R_ANKLE, R_KNEE],\n",
    "    [R_KNEE, R_HIP],\n",
    "    [R_HIP, PELVIS],\n",
    "    [L_HIP, PELVIS],\n",
    "    [L_HIP, L_KNEE],\n",
    "    [L_KNEE, L_ANKLE],\n",
    "    [PELVIS, THORAX],\n",
    "    [THORAX, UPPER_NECK],\n",
    "    [UPPER_NECK, HEAD_TOP],\n",
    "    [R_WRIST, R_ELBOW],\n",
    "    [R_ELBOW, R_SHOULDER],\n",
    "    [THORAX, R_SHOULDER],\n",
    "    [THORAX, L_SHOULDER],\n",
    "    [L_SHOULDER, L_ELBOW],\n",
    "    [L_ELBOW, L_WRIST]\n",
    "]\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5399119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_coordinates(heatmaps):\n",
    "    flatten_heatmaps = tf.reshape(heatmaps, (-1, 16))\n",
    "    indices = tf.math.argmax(flatten_heatmaps, axis=0)\n",
    "    y = tf.cast(indices / 64, dtype=tf.int64)\n",
    "    x = indices - 64 * y\n",
    "    return tf.stack([x, y], axis=1).numpy()\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints_from_heatmap(heatmaps):\n",
    "    max_keypoints = find_max_coordinates(heatmaps)\n",
    "\n",
    "    padded_heatmap = np.pad(heatmaps, [[1,1],[1,1],[0,0]], mode='constant')\n",
    "    adjusted_keypoints = []\n",
    "    for i, keypoint in enumerate(max_keypoints):\n",
    "        max_y = keypoint[1]+1\n",
    "        max_x = keypoint[0]+1\n",
    "        \n",
    "        patch = padded_heatmap[max_y-1:max_y+2, max_x-1:max_x+2, i]\n",
    "        patch[1][1] = 0\n",
    "        \n",
    "        index = np.argmax(patch)\n",
    "        \n",
    "        next_y = index // 3\n",
    "        next_x = index - next_y * 3\n",
    "        delta_y = (next_y - 1) / 4\n",
    "        delta_x = (next_x - 1) / 4\n",
    "        \n",
    "        adjusted_keypoint_x = keypoint[0] + delta_x\n",
    "        adjusted_keypoint_y = keypoint[1] + delta_y\n",
    "        adjusted_keypoints.append((adjusted_keypoint_x, adjusted_keypoint_y))\n",
    "        \n",
    "    adjusted_keypoints = np.clip(adjusted_keypoints, 0, 64)\n",
    "    normalized_keypoints = adjusted_keypoints / 64\n",
    "    return normalized_keypoints\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94183876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_path):\n",
    "    encoded = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_jpeg(encoded)\n",
    "    inputs = tf.image.resize(image, (256, 256))\n",
    "    inputs = tf.cast(inputs, tf.float32) / 127.5 - 1\n",
    "    inputs = tf.expand_dims(inputs, 0)\n",
    "    outputs = model(inputs, training=False)\n",
    "    if type(outputs) != list:\n",
    "        outputs = [outputs]\n",
    "    heatmap = tf.squeeze(outputs[-1], axis=0).numpy()\n",
    "    kp = extract_keypoints_from_heatmap(heatmap)\n",
    "    return image, kp\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints_on_image(image, keypoints, index=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    joints = []\n",
    "    for i, joint in enumerate(keypoints):\n",
    "        joint_x = joint[0] * image.shape[1]\n",
    "        joint_y = joint[1] * image.shape[0]\n",
    "        if index is not None and index != i:\n",
    "            continue\n",
    "        plt.scatter(joint_x, joint_y, s=10, c='red', marker='o')\n",
    "    plt.show()\n",
    "\n",
    "def draw_skeleton_on_image(image, keypoints, index=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    joints = []\n",
    "    for i, joint in enumerate(keypoints):\n",
    "        joint_x = joint[0] * image.shape[1]\n",
    "        joint_y = joint[1] * image.shape[0]\n",
    "        joints.append((joint_x, joint_y))\n",
    "    \n",
    "    for bone in MPII_BONES:\n",
    "        joint_1 = joints[bone[0]]\n",
    "        joint_2 = joints[bone[1]]\n",
    "        plt.plot([joint_1[0], joint_2[0]], [joint_1[1], joint_2[1]], linewidth=5, alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = os.path.join(PROJECT_PATH, 'test_image.jpg')\n",
    "\n",
    "image, keypoints = predict(model, test_image)\n",
    "draw_keypoints_on_image(image, keypoints)\n",
    "draw_skeleton_on_image(image, keypoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
